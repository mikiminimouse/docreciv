"""
Pipeline - –ø–æ–ª–Ω—ã–π –ø—Ä–æ–≥–æ–Ω preprocessing (3 —Ü–∏–∫–ª–∞ –ø–æ–¥—Ä—è–¥).
"""
import os
import typer
from datetime import datetime
from pathlib import Path
from typing import Optional

from ..engine.classifier import Classifier
from ..engine.converter import Converter
from ..engine.extractor import Extractor
from ..engine.merger import Merger
from ..core.config import get_cycle_paths, init_directory_structure, get_data_paths, DATA_BASE_DIR

app = typer.Typer(help="–ü–æ–ª–Ω—ã–π –ø—Ä–æ–≥–æ–Ω preprocessing")


def _determine_base_dir_from_input(input_dir: Path) -> Path:
    """
    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –±–∞–∑–æ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –∏–∑ input_dir.

    –ï—Å–ª–∏ input_dir –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è –Ω–∞ "Input", –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é.
    –ù–∞–ø—Ä–∏–º–µ—Ä: "/path/to/date/Input" -> "/path/to/date"

    Args:
        input_dir: –í—Ö–æ–¥–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è

    Returns:
        –ë–∞–∑–æ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è Processing/Merge/Exceptions
    """
    input_path = Path(input_dir)
    if input_path.name == "Input":
        return input_path.parent
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ —á–∞—Å—Ç—è–º –ø—É—Ç–∏ (–¥–ª—è —Å–ª—É—á–∞–µ–≤ –∫–æ–≥–¥–∞ Input –≤ —Å–µ—Ä–µ–¥–∏–Ω–µ –ø—É—Ç–∏)
    parts = input_path.parts
    for i, part in enumerate(parts):
        if part == "Input" and i > 0:
            return Path(*parts[:i])
    # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
    return input_path.parent


@app.command("run")
def run(
    input_dir: Path = typer.Argument(..., help="–í—Ö–æ–¥–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è (Input)"),
    output_dir: Path = typer.Argument(..., help="–í—ã—Ö–æ–¥–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è (Ready2Docling)"),
    max_cycles: int = typer.Option(3, "--max-cycles", help="–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ü–∏–∫–ª–æ–≤"),
    stop_on_exception: bool = typer.Option(
        False, "--stop-on-exception", help="–û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—Ç—å—Å—è –ø—Ä–∏ –æ—à–∏–±–∫–µ"
    ),
    dry_run: bool = typer.Option(False, "--dry-run", help="–†–µ–∂–∏–º –ø—Ä–æ–≤–µ—Ä–∫–∏"),
    verbose: bool = typer.Option(False, "--verbose", "-v", help="–ü–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥"),
    enable_mongo: bool = typer.Option(False, "--enable-mongo", help="–í–∫–ª—é—á–∏—Ç—å –∑–∞–ø–∏—Å—å –≤ MongoDB"),
    enable_tracker: bool = typer.Option(True, "--enable-tracker/--no-enable-tracker", help="–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å PipelineTracker"),
    tracker_run_id: str = typer.Option(None, "--tracker-run-id", help="–°—É—â–µ—Å—Ç–≤—É—é—â–∏–π run_id –¥–ª—è resume"),
    test_run_id: str = typer.Option(None, "--test-run-id", help="ID —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –∑–∞–ø—É—Å–∫–∞ –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫"),
):
    """
    –ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω—ã–π —Ü–∏–∫–ª preprocessing (3 —Ü–∏–∫–ª–∞ –ø–æ–¥—Ä—è–¥).

    –í—ã–ø–æ–ª–Ω—è–µ—Ç: classifier ‚Üí processing ‚Üí merge –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ü–∏–∫–ª–∞.

    –ü—Ä–∏ –≤–∫–ª—é—á—ë–Ω–Ω–æ–º --enable-mongo –∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –≤ MongoDB.
    –ü—Ä–∏ –≤–∫–ª—é—á—ë–Ω–Ω–æ–º --enable-tracker —Å–æ–∑–¥–∞—ë—Ç PipelineRun —á–µ—Ä–µ–∑ Docreciv PipelineTracker.
    –ü—Ä–∏ —É–∫–∞–∑–∞–Ω–∏–∏ --test-run-id —Å–æ–∑–¥–∞—ë—Ç –¥–µ—Ç–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –¥–ª—è —Ç–µ—Å—Ç–æ–≤.
    """
    if verbose:
        typer.echo(f"–ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ pipeline: {input_dir} -> {output_dir}")

    if dry_run:
        typer.echo("üîç –†–ï–ñ–ò–ú DRY RUN - –∏–∑–º–µ–Ω–µ–Ω–∏—è –Ω–µ –±—É–¥—É—Ç –ø—Ä–∏–º–µ–Ω–µ–Ω—ã")

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º MongoDB –∫–ª–∏–µ–Ω—Ç –µ—Å–ª–∏ –∑–∞–ø—Ä–æ—à–µ–Ω–æ
    db_client = None
    pipeline_id = None
    tracker_run_id = tracker_run_id  # –õ–æ–∫–∞–ª—å–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è run_id –∏–∑ PipelineTracker
    metrics_collector = None  # –î–ª—è –¥–µ—Ç–∞–ª—å–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫ —Ç–µ—Å—Ç–æ–≤—ã—Ö –∑–∞–ø—É—Å–∫–æ–≤

    if enable_mongo:
        from ..core.database import get_database

        db_client = get_database()

        if db_client.is_connected():
            typer.echo("üóÑÔ∏è  MongoDB –ø–æ–¥–∫–ª—é—á–µ–Ω–∞ - –º–µ—Ç—Ä–∏–∫–∏ –±—É–¥—É—Ç –∑–∞–ø–∏—Å—ã–≤–∞—Ç—å—Å—è")
        else:
            typer.echo("‚ö†Ô∏è  MongoDB –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ - —Ä–∞–±–æ—Ç–∞ –±–µ–∑ –∑–∞–ø–∏—Å–∏ –º–µ—Ç—Ä–∏–∫", err=True)
            db_client = None

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º PipelineTracker –µ—Å–ª–∏ –∑–∞–ø—Ä–æ—à–µ–Ω–æ
    if enable_tracker and db_client is not None and db_client.is_connected():
        try:
            from docreciv.pipeline.events import Stage, RunStatus

            # –ï—Å–ª–∏ run_id –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω, —Å–æ–∑–¥–∞—ë–º –Ω–æ–≤—ã–π PipelineRun
            if tracker_run_id is None:
                tracker_run_id = db_client.create_pipeline_run(
                    batch_date=protocol_date if 'protocol_date' in locals() else datetime.now().strftime("%Y-%m-%d"),
                    stage=Stage.DOCPREP,
                    config={
                        "max_cycles": max_cycles,
                        "input_dir": str(input_dir),
                        "output_dir": str(output_dir),
                        "dry_run": dry_run
                    }
                )
                if tracker_run_id:
                    typer.echo(f"üîó PipelineTracker run_id: {tracker_run_id}")
            else:
                typer.echo(f"üîó –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π run_id: {tracker_run_id}")

        except ImportError:
            typer.echo("‚ö†Ô∏è  PipelineTracker –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω - —Ä–∞–±–æ—Ç–∞ –±–µ–∑ —Ç—Ä–µ–∫–∏–Ω–≥–∞", err=True)
        except Exception as e:
            typer.echo(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ PipelineTracker: {e}", err=True)

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º MetricsCollector –¥–ª—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –∑–∞–ø—É—Å–∫–æ–≤
    if test_run_id:
        from ..core.metrics import MetricsCollector

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–º—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –∏–∑ MONGODB_URI –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º —É–º–æ–ª—á–∞–Ω–∏–µ
        import re
        mongo_uri = os.getenv("MONGODB_URI", "")
        if mongo_uri:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–º—è –±–∞–∑—ã –∏–∑ URI
            match = re.search(r'/([^/?]+)$', mongo_uri)
            db_name = match.group(1) if match else None
        else:
            db_name = None

        metrics_collector = MetricsCollector(
            test_run_id=test_run_id,
            db_name=db_name,
        )

        if verbose and metrics_collector.is_connected():
            typer.echo(f"üìä MetricsCollector –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω: {test_run_id}")

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–∞—Ç—É –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ –∏–∑ input_dir –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ–∫—É—â—É—é
    protocol_date = datetime.now().strftime("%Y-%m-%d")
    if "/" in str(input_dir) or "\\" in str(input_dir):
        # –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å –¥–∞—Ç—É –∏–∑ –ø—É—Ç–∏
        parts = Path(input_dir).parts
        for part in parts:
            if part and len(part) == 10 and part[4] == "-" and part[7] == "-":
                protocol_date = part
                break

    typer.echo(f"üìÖ –î–∞—Ç–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞: {protocol_date}")

    # –ö–†–ò–¢–ò–ß–ù–û: –û–ø—Ä–µ–¥–µ–ª—è–µ–º base_dir –∏–∑ input_dir –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
    # –í—Å–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ (Processing, Merge, Exceptions) –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Ä—è–¥–æ–º —Å Input
    base_dir = _determine_base_dir_from_input(input_dir)
    typer.echo(f"üìÅ –ë–∞–∑–æ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {base_dir}")

    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º DATA_BASE_DIR –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞
    # –≠—Ç–æ –Ω—É–∂–Ω–æ —á—Ç–æ–±—ã get_data_paths –∏ –¥—Ä—É–≥–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø—É—Ç—å
    os.environ["DATA_BASE_DIR"] = str(base_dir)

    # –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥—É–ª—å config –¥–ª—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –Ω–æ–≤–æ–π DATA_BASE_DIR
    import importlib
    from ..core import config as config_module
    importlib.reload(config_module)

    # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Å—ã–ª–∫–∏ –Ω–∞ —Ñ—É–Ω–∫—Ü–∏–∏ –∏–∑ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ –º–æ–¥—É–ª—è
    from ..core.config import get_data_paths as get_data_paths_updated, get_cycle_paths as get_cycle_paths_updated

    # –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º pipeline run –≤ MongoDB
    if db_client is not None and db_client.is_connected():
        pipeline_id = db_client.start_pipeline(
            input_dir=str(input_dir),
            output_dir=str(output_dir),
            protocol_date=protocol_date,
            max_cycles=max_cycles,
        )
        typer.echo(f"üìä Pipeline ID: {pipeline_id}")

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –¥–∞—Ç–æ–π
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º base_dir –Ω–∞–ø—Ä—è–º—É—é, –±–µ–∑ –≤–ª–æ–∂–µ–Ω–Ω–æ–π –¥–∞—Ç—ã (—Ç–∞–∫ –∫–∞–∫ –¥–∞—Ç–∞ —É–∂–µ –≤ –ø—É—Ç–∏)
    init_directory_structure(base_dir=base_dir, date=None)

    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º base_dir –≤ Classifier –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø—É—Ç–µ–π
    Classifier.set_base_dir(base_dir)

    classifier_engine = Classifier()
    converter_engine = Converter()
    extractor_engine = Extractor()
    merger_engine = Merger()

    # ‚òÖ UnitEvents: –ø–µ—Ä–µ–¥–∞—ë–º tracker_run_id –≤–æ –≤—Å–µ engine –∫–ª–∞—Å—Å—ã
    if tracker_run_id and db_client is not None:
        Classifier.set_tracker_run_id(tracker_run_id, db_client)
        Converter.set_tracker_run_id(tracker_run_id, db_client)
        Extractor.set_tracker_run_id(tracker_run_id, db_client)
        Merger.set_tracker_run_id(tracker_run_id, db_client)
        if verbose:
            typer.echo("‚úì UnitEvents –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω–∞")

    # –ó–∞–ø—É—Å–∫–∞–µ–º —Ü–∏–∫–ª—ã
    for cycle_num in range(1, max_cycles + 1):
        typer.echo(f"\n{'='*60}")
        typer.echo(f"üîÑ –¶–ò–ö–õ {cycle_num} –∏–∑ {max_cycles}")
        typer.echo(f"{'='*60}")

        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º cycle_run –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ —Ü–∏–∫–ª–∞
            from ..cli.cycle import cycle_run
            
            cycle_input_dir = input_dir if cycle_num == 1 else None
            
            cycle_run(
                cycle_num=cycle_num,
                input_dir=cycle_input_dir,
                protocol_date=None,  # None, —Ç–∞–∫ –∫–∞–∫ base_dir —É–∂–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É
                dry_run=dry_run,
                verbose=verbose,
                pipeline_id=pipeline_id,
                enable_mongo=enable_mongo,
            )

        except Exception as e:
            msg = f"–û—à–∏–±–∫–∞ –≤ —Ü–∏–∫–ª–µ {cycle_num}: {e}"
            if stop_on_exception:
                typer.echo(f"‚ùå {msg}", err=True)
                raise
            else:
                typer.echo(f"‚ö†Ô∏è  {msg} - –ø—Ä–æ–ø—É—Å–∫ —Ü–∏–∫–ª–∞", err=True)
                continue

    # –§–∏–Ω–∞–ª—å–Ω—ã–π merge –∏–∑ –≤—Å–µ—Ö Merge_N –≤ Ready2Docling
    typer.echo(f"\n{'='*60}")
    typer.echo("üèÅ –§–ò–ù–ê–õ–¨–ù–´–ô MERGE –≤ Ready2Docling")
    typer.echo(f"{'='*60}")

    # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –ø—É—Ç–∏ –¥–ª—è merge –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
    # –ù–û–í–ê–Ø –°–¢–†–£–ö–¢–£–†–ê v2:
    # - Merge/Direct/ - –¥–ª—è –ø—Ä—è–º—ã—Ö —Ñ–∞–π–ª–æ–≤ –≥–æ—Ç–æ–≤—ã—Ö –∫ Docling (–±–µ–∑ –æ–±—Ä–∞–±–æ—Ç–∫–∏)
    # - Merge/Processing_N/ - –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö units –≤ —Ü–∏–∫–ª–µ N

    # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü–µ—Ä–µ–¥–∞—ë–º base_dir —è–≤–Ω–æ —á—Ç–æ–±—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –ø—É—Ç–∏
    # –ü–æ—Å–ª–µ reload config_module, DATA_BASE_DIR –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –æ–±–Ω–æ–≤–ª–µ–Ω–∞,
    # –Ω–æ –ø–µ—Ä–µ–¥–∞—ë–º base_dir —è–≤–Ω–æ –¥–ª—è –Ω–∞–¥—ë–∂–Ω–æ—Å—Ç–∏
    data_paths = get_data_paths_updated(date=None, base_dir=base_dir)
    merge_dirs = []

    # –î–æ–±–∞–≤–ª—è–µ–º Merge/Direct –¥–ª—è direct —Ñ–∞–π–ª–æ–≤ –∏–∑ —Ü–∏–∫–ª–∞ 1
    merge_direct = data_paths["merge"] / "Direct"
    if merge_direct.exists():
        merge_dirs.append(merge_direct)

    # –î–æ–±–∞–≤–ª—è–µ–º –≤—Å–µ Merge/Processed_N (1, 2, 3)
    for cycle_num in range(1, max_cycles + 1):
        cycle_paths = get_cycle_paths_updated(
            cycle_num,
            data_paths["processing"],
            data_paths["merge"],
            data_paths["exceptions"]
        )
        if cycle_paths["merge"].exists():
             merge_dirs.append(cycle_paths["merge"])

    typer.echo(f"üîç –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–ª—è Merge: {[d.name for d in merge_dirs]}")
    
    # –ü–æ–ª—É—á–∞–µ–º er_merge_base –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ merge
    er_merge_base = data_paths.get("er_merge")
    
    try:
        result = merger_engine.collect_units(merge_dirs, output_dir, cycle=None, er_merge_base=er_merge_base)
        typer.echo(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {result['units_processed']} UNITs")
        
        if result.get("errors"):
            typer.echo(f"‚ö†Ô∏è  –û—à–∏–±–æ–∫: {len(result['errors'])}", err=True)
            if verbose:
                for error in result["errors"][:10]:
                    typer.echo(f"  ‚ùå {error.get('unit_id', 'unknown')}: {error.get('error')}", err=True)
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        ready_units = list(output_dir.rglob("UNIT_*")) if output_dir.exists() else []
        typer.echo(f"üìÅ UNITs –≤ Ready2Docling: {len(ready_units)}")

        # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –≤ MongoDB
        if db_client is not None and db_client.is_connected() and pipeline_id:
            db_client.update_pipeline_metrics(pipeline_id, {
                "units_total": len(ready_units) + len(result.get("errors", [])),
                "units_success": len(ready_units),
                "units_failed": len(result.get("errors", [])),
            })

        # –û—á–∏—Å—Ç–∫–∞ —Ç–æ–ª—å–∫–æ –ø—Ä–∏ —É—Å–ø–µ—à–Ω–æ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ –∏ –µ—Å–ª–∏ –Ω–µ dry_run
        if not dry_run and result['units_processed'] > 0:
            _cleanup_intermediate_dirs(merge_dirs, data_paths, max_cycles, typer)

        # –ó–∞–≤–µ—Ä—à–∞–µ–º pipeline –≤ MongoDB (—É—Å–ø–µ—à–Ω–æ)
        if db_client is not None and db_client.is_connected() and pipeline_id:
            db_client.end_pipeline(pipeline_id, status="completed")

        # –û–±–Ω–æ–≤–ª—è–µ–º PipelineTracker (—É—Å–ø–µ—à–Ω–æ)
        if tracker_run_id and db_client is not None and db_client.is_connected():
            try:
                from docreciv.pipeline.events import RunStatus

                ready_units_list = list(output_dir.rglob("UNIT_*")) if output_dir.exists() else []
                final_metrics = {
                    "units_total": len(ready_units_list) + len(result.get("errors", [])),
                    "units_success": len(ready_units_list),
                    "units_failed": len(result.get("errors", [])),
                    "cycles_completed": max_cycles
                }

                db_client.update_pipeline_run(
                    run_id=tracker_run_id,
                    status=RunStatus.COMPLETED,
                    metrics=final_metrics
                )
                typer.echo("‚úÖ PipelineTracker –æ–±–Ω–æ–≤–ª—ë–Ω: COMPLETED")
            except Exception as e:
                typer.echo(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è PipelineTracker: {e}", err=True)

        # –ó–∞–≤–µ—Ä—à–∞–µ–º MetricsCollector —Å —Ñ–∏–Ω–∞–ª—å–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
        if metrics_collector is not None:
            from ..utils.paths import find_units

            ready_units_list = list(find_units(output_dir)) if output_dir.exists() else []
            units_with_files = 0

            for unit_path in ready_units_list:
                files = list(unit_path.glob("*"))
                data_files = [
                    f for f in files
                    if f.is_file() and f.name not in ["manifest.json", "audit.log.jsonl"]
                ]
                if data_files:
                    units_with_files += 1

            final_stats = {
                "total_units": len(ready_units_list),
                "units_with_files": units_with_files,
                "output_dir": str(output_dir),
            }

            metrics_collector.end_test_run(
                units_success=units_with_files,
                units_failed=len(ready_units_list) - units_with_files,
                units_total=len(ready_units_list),
                final_stats=final_stats,
            )

            if verbose:
                typer.echo(f"üìä MetricsCollector –∑–∞–≤–µ—Ä—à—ë–Ω: {metrics_collector.test_run_id}")

    except Exception as e:
        typer.echo(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–∏–Ω–∞–ª—å–Ω–æ–º merge: {e}", err=True)

        # –ó–∞–≤–µ—Ä—à–∞–µ–º pipeline –≤ MongoDB (—Å –æ—à–∏–±–∫–æ–π)
        if db_client is not None and db_client.is_connected() and pipeline_id:
            db_client.end_pipeline(pipeline_id, status="failed", errors=[{"error": str(e)}])

        # –û–±–Ω–æ–≤–ª—è–µ–º PipelineTracker (—Å –æ—à–∏–±–∫–æ–π)
        if tracker_run_id and db_client is not None and db_client.is_connected():
            try:
                from docreciv.pipeline.events import RunStatus

                db_client.update_pipeline_run(
                    run_id=tracker_run_id,
                    status=RunStatus.FAILED,
                    error=str(e)
                )
                typer.echo("‚ö†Ô∏è  PipelineTracker –æ–±–Ω–æ–≤–ª—ë–Ω: FAILED")
            except Exception as tracker_err:
                typer.echo(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è PipelineTracker: {tracker_err}", err=True)

        # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –æ—à–∏–±–∫—É –≤ MetricsCollector
        if metrics_collector is not None:
            metrics_collector.record_error(
                unit_id="pipeline",
                operation_type="final_merge",
                error_category="pipeline_error",
                error_message=str(e),
            )
            metrics_collector.end_test_run(
                units_success=0,
                units_failed=0,
                units_total=0,
                final_stats={"error": str(e)},
            )

        raise


def _cleanup_intermediate_dirs(merge_dirs, data_paths, max_cycles, typer_instance):
    """–û—á–∏—â–∞–µ—Ç –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏.

    –ò–°–ü–†–ê–í–õ–ï–ù–û: –°–æ—Ö—Ä–∞–Ω—è–µ—Ç extension –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å –≥–æ—Ç–æ–≤—ã–º–∏ —Ñ–∞–π–ª–∞–º–∏.
    –£–¥–∞–ª—è–µ—Ç —Ç–æ–ª—å–∫–æ —Å–ª—É–∂–µ–±–Ω—ã–µ —Ñ–∞–π–ª—ã –∏ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–æ–¥–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏.
    """
    import shutil

    typer_instance.echo("üßπ –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤...")

    # –ë–µ–ª—ã–π —Å–ø–∏—Å–æ–∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π –∫–æ—Ç–æ—Ä—ã–µ –ù–ï —É–¥–∞–ª—è—é—Ç—Å—è (–≥–æ—Ç–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã)
    PRESERVED_EXTENSIONS = {
        "docx", "pdf", "xlsx", "pptx", "html", "xml", "txt",
        "jpg", "jpeg", "png", "tiff", "tif", "bmp", "gif", "webp",
        "json", "Mixed", "Direct"
    }

    # –û—á–∏—Å—Ç–∫–∞ Merge –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π ‚Äî —Ç–æ–ª—å–∫–æ —Å–ª—É–∂–µ–±–Ω—ã–µ —Ñ–∞–π–ª—ã –∏ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–æ–¥–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    for merge_dir in merge_dirs:
        if merge_dir.exists():
            try:
                for item in merge_dir.iterdir():
                    if item.is_file():
                        # –£–¥–∞–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Å–ª—É–∂–µ–±–Ω—ã–µ —Ñ–∞–π–ª—ã
                        if item.name in ["audit.log.jsonl", ".DS_Store", "Thumbs.db"]:
                            item.unlink()
                    elif item.is_dir():
                        # –ù–ï —É–¥–∞–ª—è–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è–º–∏ (–≥–æ—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã)
                        if item.name in PRESERVED_EXTENSIONS:
                            continue
                        # –£–¥–∞–ª—è–µ–º —Ç–æ–ª—å–∫–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–æ–¥–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ (Processed_N, Converted, Extracted –∏ —Ç.–¥.)
                        shutil.rmtree(item)
            except Exception as e:
                typer_instance.echo(f"  ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ {merge_dir}: {e}", err=True)

    # –û—á–∏—Å—Ç–∫–∞ Processing –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π ‚Äî –ø–æ–ª–Ω–æ—Å—Ç—å—é
    processing_base = data_paths["processing"]
    for cycle_num in range(1, max_cycles + 1):
        cycle_processing_dir = processing_base / f"Processing_{cycle_num}"
        if cycle_processing_dir.exists():
            try:
                shutil.rmtree(cycle_processing_dir)
                cycle_processing_dir.mkdir()
            except Exception as e:
                typer_instance.echo(f"  ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ {cycle_processing_dir}: {e}", err=True)

    typer_instance.echo("‚úÖ –û—á–∏—Å—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")


if __name__ == "__main__":
    app()


