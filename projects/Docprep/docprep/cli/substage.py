"""
Substage - –∞—Ç–æ–º–∞—Ä–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ (convert, extract, normalize).
"""
import time
import logging
import typer
try:
    from typer.models import OptionInfo
except ImportError:
    # Typer < 0.4.0 uses typer.models.OptionInfo
    # Typer >= 0.4.0 might put it elsewhere or it is accessible
    # This is a safe fallback if imports change
    OptionInfo = typer.models.OptionInfo

from pathlib import Path
from typing import Optional, Any
from datetime import datetime

from ..engine.converter import Converter
from ..engine.extractor import Extractor
from ..engine.normalizers import NameNormalizer, ExtensionNormalizer
from ..core.unit_processor import process_directory_units
from ..utils.paths import find_all_units

logger = logging.getLogger(__name__)

app = typer.Typer(name="substage", help="–ê—Ç–æ–º–∞—Ä–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏")


def _unwrap(val: Any) -> Any:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏–∑ OptionInfo, –µ—Å–ª–∏ –æ–Ω–æ –ø–µ—Ä–µ–¥–∞–Ω–æ."""
    if isinstance(val, OptionInfo):
        return val.default
    return val


@app.command("convert")
def substage_convert_run(
    input_dir: Path = typer.Option(..., "--input", help="–í—Ö–æ–¥–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è"),
    cycle: int = typer.Option(1, "--cycle", help="–ù–æ–º–µ—Ä —Ü–∏–∫–ª–∞ (1, 2, 3)"),
    from_format: Optional[str] = typer.Option(None, "--from", help="–ò—Å—Ö–æ–¥–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç"),
    to_format: Optional[str] = typer.Option(None, "--to", help="–¶–µ–ª–µ–≤–æ–π —Ñ–æ—Ä–º–∞—Ç"),
    engine: str = typer.Option("libreoffice", "--engine", help="–î–≤–∏–∂–æ–∫ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏"),
    use_headless: bool = typer.Option(False, "--use-headless", help="–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å headless –∫–æ–Ω–≤–µ—Ä—Ç–µ—Ä (—Ä–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—ã —Å X11)"),
    mock_mode: bool = typer.Option(False, "--mock-mode", help="–†–µ–∂–∏–º —Å–∏–º—É–ª—è—Ü–∏–∏ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"),
    protocol_date: Optional[str] = typer.Option(None, "--date", help="–î–∞—Ç–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ (YYYY-MM-DD)"),
    verbose: bool = typer.Option(False, "--verbose", "-v", help="–ü–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥"),
    dry_run: bool = typer.Option(False, "--dry-run", help="–†–µ–∂–∏–º –∏–º–∏—Ç–∞—Ü–∏–∏"),
    pipeline_id: Optional[str] = typer.Option(None, "--pipeline-id", help="ID pipeline –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"),
    enable_mongo: bool = typer.Option(False, "--enable-mongo", help="–í–∫–ª—é—á–∏—Ç—å –∑–∞–ø–∏—Å—å –≤ MongoDB"),
):
    """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Ñ–æ—Ä–º–∞—Ç–æ–≤ (doc‚Üídocx –∏ —Ç.–¥.)."""
    # Unwrap arguments if called programmatically
    input_dir = _unwrap(input_dir)
    cycle = _unwrap(cycle)
    from_format = _unwrap(from_format)
    to_format = _unwrap(to_format)
    engine = _unwrap(engine)
    use_headless = _unwrap(use_headless)
    mock_mode = _unwrap(mock_mode)
    protocol_date = _unwrap(protocol_date)
    verbose = _unwrap(verbose)
    dry_run = _unwrap(dry_run)
    pipeline_id = _unwrap(pipeline_id)
    enable_mongo = _unwrap(enable_mongo)

    if not input_dir.exists():
        typer.echo(f"‚ùå –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {input_dir}", err=True)
        raise typer.Exit(1)

    # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ù–µ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ–∫—É—â—É—é –¥–∞—Ç—É –µ—Å–ª–∏ base_dir —É–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω
    from ..engine.classifier import Classifier
    if not protocol_date:
        if Classifier._override_base_dir is None:
            protocol_date = datetime.now().strftime("%Y-%m-%d")

    typer.echo(f"üîÑ –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è: {input_dir} (—Ü–∏–∫–ª {cycle})")

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º MongoDB –∫–ª–∏–µ–Ω—Ç –µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è
    db_client = None
    if enable_mongo:
        from ..core.database import get_database
        db_client = get_database()

    # –î–ª—è —Å–±–æ—Ä–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    conversion_counter: dict = {}
    unit_results: list = []
    start_time = time.time()

    converter = Converter(use_headless=use_headless, mock_mode=mock_mode)

    def process_unit(unit_path: Path) -> dict:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ UNIT –∫–æ–Ω–≤–µ—Ä—Ç–µ—Ä–æ–º."""
        result = converter.convert_unit(
            unit_path=unit_path,
            cycle=cycle,
            from_format=from_format,
            to_format=to_format,
            engine=engine,
            protocol_date=protocol_date,
            dry_run=dry_run,
        )
        files_converted = result.get('files_converted', 0)
        from_ext = result.get('from_extension', 'unknown')
        to_ext = result.get('to_extension', 'unknown')

        # –°–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        key = f"{from_ext}->{to_ext}"
        conversion_counter[key] = conversion_counter.get(key, 0) + files_converted

        unit_results.append({
            "unit_id": unit_path.name,
            "files_converted": files_converted,
            "from_extension": from_ext,
            "to_extension": to_ext,
            "status": result.get('status', 'success'),
        })

        if verbose:
            typer.echo(f"  ‚úì {unit_path.name}: {files_converted} —Ñ–∞–π–ª–æ–≤ ({from_ext}->{to_ext})")
        return result

    results = process_directory_units(
        source_dir=input_dir,
        processor_func=process_unit,
        dry_run=dry_run,
    )

    processing_time_ms = int((time.time() - start_time) * 1000)

    typer.echo(f"\n‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ UNIT: {results['units_processed']}")
    if results['units_failed'] > 0:
        typer.echo(f"‚ùå –û—à–∏–±–æ–∫: {results['units_failed']}", err=True)

    # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤ MongoDB
    if enable_mongo and db_client and pipeline_id and not dry_run:
        try:
            total_files_converted = sum(conversion_counter.values())
            stage_stats = {
                "total_units": results['units_processed'],
                "units_failed": results['units_failed'],
                "total_files_converted": total_files_converted,
                "by_conversion": conversion_counter,
                "processing_time_ms": processing_time_ms,
                "engine": engine,
            }
            db_client.write_stage_stats(
                pipeline_id=pipeline_id,
                cycle=cycle,
                stage="convert",
                stats=stage_stats,
            )

            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º trace –¥–ª—è –∫–∞–∂–¥–æ–≥–æ UNIT
            for unit_res in unit_results:
                db_client.write_unit_trace(
                    unit_id=unit_res["unit_id"],
                    pipeline_id=pipeline_id,
                    cycle=cycle,
                    stage="convert",
                    operation="convert",
                    duration_ms=0,
                    status=unit_res["status"],
                    metadata={
                        "files_converted": unit_res["files_converted"],
                        "from_extension": unit_res["from_extension"],
                        "to_extension": unit_res["to_extension"],
                    },
                )

            if verbose:
                typer.echo(f"üíæ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –∑–∞–ø–∏—Å–∞–Ω–∞ –≤ MongoDB")
        except Exception as e:
            logger.warning(f"Failed to write convert stats to MongoDB: {e}")
            typer.echo(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø–∏—Å–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É: {e}", err=True)


@app.command("extract")
def substage_extract_run(
    input_dir: Path = typer.Option(..., "--input", help="–í—Ö–æ–¥–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è"),
    cycle: int = typer.Option(1, "--cycle", help="–ù–æ–º–µ—Ä —Ü–∏–∫–ª–∞ (1, 2, 3)"),
    max_depth: int = typer.Option(2, "--max-depth", help="–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≥–ª—É–±–∏–Ω–∞"),
    keep_archive: bool = typer.Option(False, "--keep-archive", help="–°–æ—Ö—Ä–∞–Ω—è—Ç—å –∞—Ä—Ö–∏–≤"),
    flatten: bool = typer.Option(False, "--flatten", help="–†–∞–∑–º–µ—â–∞—Ç—å –≤—Å–µ –≤ –æ–¥–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏"),
    protocol_date: Optional[str] = typer.Option(None, "--date", help="–î–∞—Ç–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ (YYYY-MM-DD)"),
    verbose: bool = typer.Option(False, "--verbose", "-v", help="–ü–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥"),
    dry_run: bool = typer.Option(False, "--dry-run", help="–†–µ–∂–∏–º –∏–º–∏—Ç–∞—Ü–∏–∏"),
    pipeline_id: Optional[str] = typer.Option(None, "--pipeline-id", help="ID pipeline –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"),
    enable_mongo: bool = typer.Option(False, "--enable-mongo", help="–í–∫–ª—é—á–∏—Ç—å –∑–∞–ø–∏—Å—å –≤ MongoDB"),
):
    """–†–∞–∑–∞—Ä—Ö–∏–≤–∞—Ü–∏—è –∞—Ä—Ö–∏–≤–æ–≤."""
    # Unwrap arguments
    input_dir = _unwrap(input_dir)
    cycle = _unwrap(cycle)
    max_depth = _unwrap(max_depth)
    keep_archive = _unwrap(keep_archive)
    flatten = _unwrap(flatten)
    protocol_date = _unwrap(protocol_date)
    verbose = _unwrap(verbose)
    dry_run = _unwrap(dry_run)
    pipeline_id = _unwrap(pipeline_id)
    enable_mongo = _unwrap(enable_mongo)

    if not input_dir.exists():
        typer.echo(f"‚ùå –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {input_dir}", err=True)
        raise typer.Exit(1)

    # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ù–µ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ–∫—É—â—É—é –¥–∞—Ç—É –µ—Å–ª–∏ base_dir —É–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω
    from ..engine.classifier import Classifier
    if not protocol_date:
        if Classifier._override_base_dir is None:
            protocol_date = datetime.now().strftime("%Y-%m-%d")

    typer.echo(f"üì¶ –†–∞–∑–∞—Ä—Ö–∏–≤–∞—Ü–∏—è: {input_dir} (—Ü–∏–∫–ª {cycle})")

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º MongoDB –∫–ª–∏–µ–Ω—Ç –µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è
    db_client = None
    if enable_mongo:
        from ..core.database import get_database
        db_client = get_database()

    # –î–ª—è —Å–±–æ—Ä–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    archive_type_counter: dict = {}
    unit_results: list = []
    start_time = time.time()

    extractor = Extractor()

    def process_unit(unit_path: Path) -> dict:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ UNIT —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–æ–º."""
        result = extractor.extract_unit(
            unit_path=unit_path,
            cycle=cycle,
            max_depth=max_depth,
            keep_archive=keep_archive,
            flatten=flatten,
            protocol_date=protocol_date,
            dry_run=dry_run,
        )
        files_extracted = result.get('files_extracted', 0)
        archive_type = result.get('archive_type', 'unknown')

        # –°–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        archive_type_counter[archive_type] = archive_type_counter.get(archive_type, 0) + files_extracted

        unit_results.append({
            "unit_id": unit_path.name,
            "files_extracted": files_extracted,
            "archive_type": archive_type,
            "status": result.get('status', 'success'),
        })

        if verbose:
            typer.echo(f"  ‚úì {unit_path.name}: {files_extracted} —Ñ–∞–π–ª–æ–≤ ({archive_type})")
        return result

    results = process_directory_units(
        source_dir=input_dir,
        processor_func=process_unit,
        dry_run=dry_run,
    )

    processing_time_ms = int((time.time() - start_time) * 1000)

    typer.echo(f"\n‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ UNIT: {results['units_processed']}")
    if results['units_failed'] > 0:
        typer.echo(f"‚ùå –û—à–∏–±–æ–∫: {results['units_failed']}", err=True)

    # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤ MongoDB
    if enable_mongo and db_client and pipeline_id and not dry_run:
        try:
            total_files_extracted = sum(archive_type_counter.values())
            stage_stats = {
                "total_units": results['units_processed'],
                "units_failed": results['units_failed'],
                "total_files_extracted": total_files_extracted,
                "by_archive_type": archive_type_counter,
                "processing_time_ms": processing_time_ms,
                "max_depth": max_depth,
            }
            db_client.write_stage_stats(
                pipeline_id=pipeline_id,
                cycle=cycle,
                stage="extract",
                stats=stage_stats,
            )

            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º trace –¥–ª—è –∫–∞–∂–¥–æ–≥–æ UNIT
            for unit_res in unit_results:
                db_client.write_unit_trace(
                    unit_id=unit_res["unit_id"],
                    pipeline_id=pipeline_id,
                    cycle=cycle,
                    stage="extract",
                    operation="extract",
                    duration_ms=0,
                    status=unit_res["status"],
                    metadata={
                        "files_extracted": unit_res["files_extracted"],
                        "archive_type": unit_res["archive_type"],
                    },
                )

            if verbose:
                typer.echo(f"üíæ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∑–∞–ø–∏—Å–∞–Ω–∞ –≤ MongoDB")
        except Exception as e:
            logger.warning(f"Failed to write extract stats to MongoDB: {e}")
            typer.echo(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø–∏—Å–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É: {e}", err=True)


@app.command("normalize")
def substage_normalize_name(
    input_dir: Path = typer.Option(..., "--input", help="–í—Ö–æ–¥–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è"),
    cycle: int = typer.Option(1, "--cycle", help="–ù–æ–º–µ—Ä —Ü–∏–∫–ª–∞ (1, 2, 3)"),
    protocol_date: Optional[str] = typer.Option(None, "--date", help="–î–∞—Ç–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ (YYYY-MM-DD)"),
    verbose: bool = typer.Option(False, "--verbose", "-v", help="–ü–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥"),
    dry_run: bool = typer.Option(False, "--dry-run", help="–†–µ–∂–∏–º –∏–º–∏—Ç–∞—Ü–∏–∏"),
):
    """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ (–¢–û–õ–¨–ö–û –∏–º—è)."""
    # Unwrap arguments
    input_dir = _unwrap(input_dir)
    cycle = _unwrap(cycle)
    protocol_date = _unwrap(protocol_date)
    verbose = _unwrap(verbose)
    dry_run = _unwrap(dry_run)

    if not input_dir.exists():
        typer.echo(f"‚ùå –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {input_dir}", err=True)
        raise typer.Exit(1)

    # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ù–µ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ–∫—É—â—É—é –¥–∞—Ç—É –µ—Å–ª–∏ base_dir —É–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω
    from ..engine.classifier import Classifier
    if not protocol_date:
        if Classifier._override_base_dir is None:
            protocol_date = datetime.now().strftime("%Y-%m-%d")

    typer.echo(f"üìù –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∏–º–µ–Ω: {input_dir} (—Ü–∏–∫–ª {cycle})")
    
    normalizer = NameNormalizer()
    
    def process_unit(unit_path: Path) -> dict:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ UNIT –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–º –∏–º–µ–Ω."""
        result = normalizer.normalize_names(
            unit_path=unit_path,
            cycle=cycle,
            protocol_date=protocol_date,
            dry_run=dry_run,
        )
        if verbose:
            typer.echo(f"  ‚úì {unit_path.name}: {result.get('files_normalized', 0)} —Ñ–∞–π–ª–æ–≤")
        return result

    results = process_directory_units(
        source_dir=input_dir,
        processor_func=process_unit,
        dry_run=dry_run,
    )

    typer.echo(f"\n‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ UNIT: {results['units_processed']}")
    if results['units_failed'] > 0:
        typer.echo(f"‚ùå –û—à–∏–±–æ–∫: {results['units_failed']}", err=True)


@app.command("normalize-extension")
def substage_normalize_extension(
    input_dir: Path = typer.Option(..., "--input", help="–í—Ö–æ–¥–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è"),
    cycle: int = typer.Option(1, "--cycle", help="–ù–æ–º–µ—Ä —Ü–∏–∫–ª–∞ (1, 2, 3)"),
    protocol_date: Optional[str] = typer.Option(None, "--date", help="–î–∞—Ç–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ (YYYY-MM-DD)"),
    verbose: bool = typer.Option(False, "--verbose", "-v", help="–ü–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥"),
    dry_run: bool = typer.Option(False, "--dry-run", help="–†–µ–∂–∏–º –∏–º–∏—Ç–∞—Ü–∏–∏"),
):
    """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è (–ø–æ —Å–∏–≥–Ω–∞—Ç—É—Ä–∞–º)."""
    # Unwrap arguments
    input_dir = _unwrap(input_dir)
    cycle = _unwrap(cycle)
    protocol_date = _unwrap(protocol_date)
    verbose = _unwrap(verbose)
    dry_run = _unwrap(dry_run)

    if not input_dir.exists():
        typer.echo(f"‚ùå –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {input_dir}", err=True)
        raise typer.Exit(1)

    # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ù–µ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ–∫—É—â—É—é –¥–∞—Ç—É –µ—Å–ª–∏ base_dir —É–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω
    from ..engine.classifier import Classifier
    if not protocol_date:
        if Classifier._override_base_dir is None:
            protocol_date = datetime.now().strftime("%Y-%m-%d")

    typer.echo(f"üîß –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π: {input_dir} (—Ü–∏–∫–ª {cycle})")
    
    normalizer = ExtensionNormalizer()
    
    def process_unit(unit_path: Path) -> dict:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ UNIT –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π."""
        result = normalizer.normalize_extensions(
            unit_path=unit_path,
            cycle=cycle,
            protocol_date=protocol_date,
            dry_run=dry_run,
        )
        if verbose:
            typer.echo(f"  ‚úì {unit_path.name}: {result.get('files_normalized', 0)} —Ñ–∞–π–ª–æ–≤")
        return result

    results = process_directory_units(
        source_dir=input_dir,
        processor_func=process_unit,
        dry_run=dry_run,
    )

    typer.echo(f"\n‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ UNIT: {results['units_processed']}")
    if results['units_failed'] > 0:
        typer.echo(f"‚ùå –û—à–∏–±–æ–∫: {results['units_failed']}", err=True)


@app.command("normalize-full")
def substage_normalize_full(
    input_dir: Path = typer.Option(..., "--input", help="–í—Ö–æ–¥–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è"),
    cycle: int = typer.Option(1, "--cycle", help="–ù–æ–º–µ—Ä —Ü–∏–∫–ª–∞ (1, 2, 3)"),
    protocol_date: Optional[str] = typer.Option(None, "--date", help="–î–∞—Ç–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ (YYYY-MM-DD)"),
    verbose: bool = typer.Option(False, "--verbose", "-v", help="–ü–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥"),
    dry_run: bool = typer.Option(False, "--dry-run", help="–†–µ–∂–∏–º –∏–º–∏—Ç–∞—Ü–∏–∏"),
    pipeline_id: Optional[str] = typer.Option(None, "--pipeline-id", help="ID pipeline –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"),
    enable_mongo: bool = typer.Option(False, "--enable-mongo", help="–í–∫–ª—é—á–∏—Ç—å –∑–∞–ø–∏—Å—å –≤ MongoDB"),
):
    """–ü–æ–ª–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è (–∏–º—è + —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ)."""
    # Unwrap arguments
    input_dir = _unwrap(input_dir)
    cycle = _unwrap(cycle)
    protocol_date = _unwrap(protocol_date)
    verbose = _unwrap(verbose)
    dry_run = _unwrap(dry_run)
    pipeline_id = _unwrap(pipeline_id)
    enable_mongo = _unwrap(enable_mongo)

    if not input_dir.exists():
        typer.echo(f"‚ùå –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {input_dir}", err=True)
        raise typer.Exit(1)

    # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ù–µ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ–∫—É—â—É—é –¥–∞—Ç—É –µ—Å–ª–∏ base_dir —É–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω
    from ..engine.classifier import Classifier
    if not protocol_date:
        if Classifier._override_base_dir is None:
            protocol_date = datetime.now().strftime("%Y-%m-%d")

    typer.echo(f"‚ú® –ü–æ–ª–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è: {input_dir} (—Ü–∏–∫–ª {cycle})")

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º MongoDB –∫–ª–∏–µ–Ω—Ç –µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è
    db_client = None
    if enable_mongo:
        from ..core.database import get_database
        db_client = get_database()

    # –î–ª—è —Å–±–æ—Ä–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    names_normalized = 0
    extensions_normalized = 0
    unit_results: list = []
    start_time = time.time()

    name_normalizer = NameNormalizer()
    ext_normalizer = ExtensionNormalizer()

    def process_unit(unit_path: Path) -> dict:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ UNIT –ø–æ–ª–Ω–æ–π –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π."""
        # –°–Ω–∞—á–∞–ª–∞ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∏–º–µ–Ω–∞
        name_result = name_normalizer.normalize_names(
            unit_path=unit_path,
            cycle=cycle,
            protocol_date=protocol_date,
            dry_run=dry_run,
        )
        # –ó–∞—Ç–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è (–Ω–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–Ω–æ–º –ø—É—Ç–∏)
        updated_path = Path(name_result.get("target_directory", unit_path))
        ext_result = ext_normalizer.normalize_extensions(
            unit_path=updated_path,
            cycle=cycle,
            protocol_date=protocol_date,
            dry_run=dry_run,
        )

        names_count = name_result.get('files_normalized', 0)
        ext_count = ext_result.get('files_normalized', 0)

        # –°–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        nonlocal names_normalized, extensions_normalized
        names_normalized += names_count
        extensions_normalized += ext_count

        unit_results.append({
            "unit_id": unit_path.name,
            "names_normalized": names_count,
            "extensions_normalized": ext_count,
            "status": name_result.get('status', 'success'),
        })

        if verbose:
            typer.echo(f"  ‚úì {unit_path.name}: {names_count} –∏–º–µ–Ω, {ext_count} —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π")
        return {
            "name_normalization": name_result,
            "extension_normalization": ext_result,
        }

    results = process_directory_units(
        source_dir=input_dir,
        processor_func=process_unit,
        dry_run=dry_run,
    )

    processing_time_ms = int((time.time() - start_time) * 1000)

    typer.echo(f"\n‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ UNIT: {results['units_processed']}")
    if results['units_failed'] > 0:
        typer.echo(f"‚ùå –û—à–∏–±–æ–∫: {results['units_failed']}", err=True)

    # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤ MongoDB
    if enable_mongo and db_client and pipeline_id and not dry_run:
        try:
            stage_stats = {
                "total_units": results['units_processed'],
                "units_failed": results['units_failed'],
                "total_names_normalized": names_normalized,
                "total_extensions_normalized": extensions_normalized,
                "processing_time_ms": processing_time_ms,
            }
            db_client.write_stage_stats(
                pipeline_id=pipeline_id,
                cycle=cycle,
                stage="normalize",
                stats=stage_stats,
            )

            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º trace –¥–ª—è –∫–∞–∂–¥–æ–≥–æ UNIT
            for unit_res in unit_results:
                db_client.write_unit_trace(
                    unit_id=unit_res["unit_id"],
                    pipeline_id=pipeline_id,
                    cycle=cycle,
                    stage="normalize",
                    operation="normalize_full",
                    duration_ms=0,
                    status=unit_res["status"],
                    metadata={
                        "names_normalized": unit_res["names_normalized"],
                        "extensions_normalized": unit_res["extensions_normalized"],
                    },
                )

            if verbose:
                typer.echo(f"üíæ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –∑–∞–ø–∏—Å–∞–Ω–∞ –≤ MongoDB")
        except Exception as e:
            logger.warning(f"Failed to write normalize stats to MongoDB: {e}")
            typer.echo(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø–∏—Å–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É: {e}", err=True)


